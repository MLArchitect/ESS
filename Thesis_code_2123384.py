# -*- coding: utf-8 -*-
"""thesis_code.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1Ea2lK_kogh4N7pJcSX1AWN-gl8dyCo0X
"""

# LOad RAW data
# read the file
import pandas as pd
df_raw= pd.read_csv("/content/ESS11.csv")
print(len(df_raw))
print("\ncolumns")
print(df_raw.columns)
print(df_raw.shape)

# Feature Selection
column_mapping = {

    'happy': 'Happiness',
    'agea': 'Age',
    'sclmeet': 'Social Meeting Frequency',
    'inprdsc': 'Intimate Discussion Frequency',
    'sclact': 'Social Activity Participation',
    'fltlnl': 'Felt Lonely',
    'health': 'Health Status',
    'hlthhmp': 'Health Hampering Activities',
    'hincfel': 'Feeling About Household Income',
    'hinctnta': 'Household Total Net Income',
    'fltsd': 'Felt Sad',
    'flteeff': 'Felt Everything Was an Effort',
    'ppltrst': 'Trust in People',
    'rlgdgr': 'Religiosity',
    'gndr': 'Gender',
    'dscrrce': 'Discrimination by Race/Color',
    'uempli': 'Unemployed, Not Actively Looking',
    'hltprsd': 'Health Problems (Stomach/Digestion)',
    'hltprhb': 'Health Problems (High Blood Pressure)',
    'trstprl': 'Trust in Parliament',
    'stflife': 'Life Satisfaction',
    'stfeco': 'Satisfaction with Economy',
    'domicil': 'Area of Living',
    'eisced': 'Highest Level of Education',
    'netusoft': 'Internet Use Frequency',
    'stfgov': 'Satisfaction with the National Government',
    'stfdem': 'Satisfaction with Democracy',
    'stfedu': 'Assessment of the State of Education',
    'stfhlth': 'Assessment of Health Services',
    'trstlgl': 'Trust in the Legal System',
    'trstplc': 'Trust in the Police',
    'trstplt': 'Trust in Politicians',
    'trstprt': 'Trust in Political Parties',
    'trstep': 'Trust in the European Parliament',
    'trstun': 'Trust in the United Nations',
    'slprl' : 'Sleep was restless, how often past week'

}
# Define the selected columns
selected_columns = [
    'happy', 'sclmeet', 'inprdsc', 'sclact', 'fltlnl', 'health', 'hlthhmp',
    'hincfel', 'hinctnta', 'fltsd', 'flteeff', 'ppltrst', 'rlgdgr', 'gndr',
    'agea', 'dscrrce', 'uempli', 'hltprsd', 'hltprhb', 'trstprl', 'stflife',
    'stfeco', 'domicil', 'eisced', 'netusoft',
    'stfgov', 'stfdem', 'stfedu', 'stfhlth', 'trstlgl', 'trstplc',
    'trstplt', 'trstprt', 'trstep', 'trstun','slprl'
]

# Select the columns from df_raw
dfsmall = df_raw[selected_columns]

# Survey Dictionariy
survey_dict = {
    'happy': {
        0: "Extremely unhappy",
        1: "1",
        2: "2",
        3: "3",
        4: "4",
        5: "5",
        6: "6",
        7: "7",
        8: "8",
        9: "9",
        10: "Extremely happy",
        77: "Refusal*",
        88: "Don't know*",
        99: "No answer*"
    },
    'sclmeet': {
        1: "Never",
        2: "Less than once a month",
        3: "Once a month",
        4: "Several times a month",
        5: "Once a week",
        6: "Several times a week",
        7: "Every day",
        77: "Refusal*",
        88: "Don't know*",
        99: "No answer*"
    },
    'inprdsc': {
        0: "None",
        1: "1",
        2: "2",
        3: "3",
        4: "4-6",
        5: "7-9",
        6: "10 or more",
        77: "Refusal*",
        88: "Don't know*",
        99: "No answer*"
    },
    'sclact': {
        1: "Much less than most",
        2: "Less than most",
        3: "About the same",
        4: "More than most",
        5: "Much more than most",
        7: "Refusal*",
        8: "Don't know*",
        9: "No answer*"
    },
    'fltlnl': {
        1: "None or almost none of the time",
        2: "Some of the time",
        3: "Most of the time",
        4: "All or almost all of the time",
        7: "Refusal*",
        8: "Don't know*",
        9: "No answer*"
    },
    'health': {
        1: "Very good",
        2: "Good",
        3: "Fair",
        4: "Bad",
        5: "Very bad",
        7: "Refusal*",
        8: "Don't know*",
        9: "No answer*"
    },
    'hlthhmp': {
        1: "Yes a lot",
        2: "Yes to some extent",
        3: "No",
        7: "Refusal*",
        8: "Don't know*",
        9: "No answer*"
    },
    'hincfel': {
        1: "Living comfortably on present income",
        2: "Coping on present income",
        3: "Difficult on present income",
        4: "Very difficult on present income",
        7: "Refusal*",
        8: "Don't know*",
        9: "No answer*"
    },
    'hinctnta': {
        1: "J - 1st decile",
        2: "R - 2nd decile",
        3: "C - 3rd decile",
        4: "M - 4th decile",
        5: "F - 5th decile",
        6: "S - 6th decile",
        7: "K - 7th decile",
        8: "P - 8th decile",
        9: "D - 9th decile",
        10: "H - 10th decile",
        77: "Refusal*",
        88: "Don't know*",
        99: "No answer*"
    },
    'fltsd': {
        1: "None or almost none of the time",
        2: "Some of the time",
        3: "Most of the time",
        4: "All or almost all of the time",
        7: "Refusal*",
        8: "Don't know*",
        9: "No answer*"
    },
    'flteeff': {
        1: "None or almost none of the time",
        2: "Some of the time",
        3: "Most of the time",
        4: "All or almost all of the time",
        7: "Refusal*",
        8: "Don't know*",
        9: "No answer*"
    },
    'ppltrst': {
        0: "You can't be too careful",
        1: "1",
        2: "2",
        3: "3",
        4: "4",
        5: "5",
        6: "6",
        7: "7",
        8: "8",
        9: "9",
        10: "Most people can be trusted",
        77: "Refusal*",
        88: "Don't know*",
        99: "No answer*"
    },
    'rlgdgr': {
        0: "Not at all religious",
        1: "1",
        2: "2",
        3: "3",
        4: "4",
        5: "5",
        6: "6",
        7: "7",
        8: "8",
        9: "9",
        10: "Very religious",
        77: "Refusal*",
        88: "Don't know*",
        99: "No answer*"
    },
    'gndr': {
        1: "Male",
        2: "Female",
        9: "No answer*"
    },
    'agea': {
        999: "Not available*"
    },
    'dscrrce': {
        0: "Not marked",
        1: "Marked"
    },
    'uempli': {
        0: "Not marked",
        1: "Marked"
    },
    'hltprsd': {
        0: "Not marked",
        1: "Marked"
    },
    'hltprhb': {
        0: "Not marked",
        1: "Marked"
    },
    'trstprl': {
        0: "No trust at all",
        1: "1",
        2: "2",
        3: "3",
        4: "4",
        5: "5",
        6: "6",
        7: "7",
        8: "8",
        9: "9",
        10: "Complete trust",
        77: "Refusal*",
        88: "Don't know*",
        99: "No answer*"
    },
    'stflife': {
        0: "Extremely dissatisfied",
        1: "1",
        2: "2",
        3: "3",
        4: "4",
        5: "5",
        6: "6",
        7: "7",
        8: "8",
        9: "9",
        10: "Extremely satisfied",
        77: "Refusal*",
        88: "Don't know*",
        99: "No answer*"
    },
    'stfeco': {
        0: "Extremely dissatisfied",
        1: "1",
        2: "2",
        3: "3",
        4: "4",
        5: "5",
        6: "6",
        7: "7",
        8: "8",
        9: "9",
        10: "Extremely satisfied",
        77: "Refusal*",
        88: "Don't know*",
        99: "No answer*"
    },
    'domicil': {
        1: "A big city",
        2: "Suburbs or outskirts of big city",
        3: "Town or small city",
        4: "Country village",
        5: "Farm or home in countryside",
        7: "Refusal*",
        8: "Don't know*",
        9: "No answer*"
    },
    'eisced': {
        0: "Not possible to harmonise into ES-ISCED",
        1: "ES-ISCED I , less than lower secondary",
        2: "ES-ISCED II, lower secondary",
        3: "ES-ISCED IIIb, lower tier upper secondary",
        4: "ES-ISCED IIIa, upper tier upper secondary",
        5: "ES-ISCED IV, advanced vocational, sub-degree",
        6: "ES-ISCED V1, lower tertiary education, BA level",
        7: "ES-ISCED V2, higher tertiary education, >= MA level",
        55: "Other",
        77: "Refusal*",
        88: "Don't know*",
        99: "No answer*"
    },
    'netusoft': {
        1: "Never",
        2: "Only occasionally",
        3: "A few times a week",
        4: "Most days",
        5: "Every day",
        7: "Refusal*",
        8: "Don't know*",
        9: "No answer*"
    },
    'stfgov': {
        0: "Extremely dissatisfied",
        1: "1",
        2: "2",
        3: "3",
        4: "4",
        5: "5",
        6: "6",
        7: "7",
        8: "8",
        9: "9",
        10: "Extremely satisfied",
        77: "Refusal*",
        88: "Don't know*",
        99: "No answer*"
    },
    'stfdem': {
        0: "Extremely dissatisfied",
        1: "1",
        2: "2",
        3: "3",
        4: "4",
        5: "5",
        6: "6",
        7: "7",
        8: "8",
        9: "9",
        10: "Extremely satisfied",
        77: "Refusal*",
        88: "Don't know*",
        99: "No answer*"
    },
    'stfedu': {
        0: "Extremely bad",
        1: "1",
        2: "2",
        3: "3",
        4: "4",
        5: "5",
        6: "6",
        7: "7",
        8: "8",
        9: "9",
        10: "Extremely good",
        77: "Refusal*",
        88: "Don't know*",
        99: "No answer*"
    },
    'stfhlth': {
        0: "Extremely bad",
        1: "1",
        2: "2",
        3: "3",

        4: "4",
        5: "5",
        6: "6",
        7: "7",
        8: "8",
        9: "9",
        10: "Extremely good",
        77: "Refusal*",
        88: "Don't know*",
        99: "No answer*"
    },
    'trstlgl': {
        0: "No trust at all",
        1: "1",
        2: "2",
        3: "3",
        4: "4",
        5: "5",
        6: "6",
        7: "7",
        8: "8",
        9: "9",
        10: "Complete trust",
        77: "Refusal*",
        88: "Don't know*",
        99: "No answer*"
    },
    'trstplc': {
        0: "No trust at all",
        1: "1",
        2: "2",
        3: "3",
        4: "4",
        5: "5",
        6: "6",
        7: "7",
        8: "8",
        9: "9",
        10: "Complete trust",
        77: "Refusal*",
        88: "Don't know*",
        99: "No answer*"
    },
    'trstplt': {
        0: "No trust at all",
        1: "1",
        2: "2",
        3: "3",
        4: "4",
        5: "5",
        6: "6",
        7: "7",
        8: "8",
        9: "9",
        10: "Complete trust",
        77: "Refusal*",
        88: "Don't know*",
        99: "No answer*"
    },
    'trstprt': {
        0: "No trust at all",
        1: "1",
        2: "2",
        3: "3",
        4: "4",
        5: "5",
        6: "6",
        7: "7",
        8: "8",
        9: "9",
        10: "Complete trust",
        77: "Refusal*",
        88: "Don't know*",
        99: "No answer*"
    },
    'trstep': {
        0: "No trust at all",
        1: "1",
        2: "2",
        3: "3",
        4: "4",
        5: "5",
        6: "6",
        7: "7",
        8: "8",
        9: "9",
        10: "Complete trust",
        77: "Refusal*",
        88: "Don't know*",
        99: "No answer*"
    },
    'trstun': {
        0: "No trust at all",
        1: "1",
        2: "2",
        3: "3",
        4: "4",
        5: "5",
        6: "6",
        7: "7",
        8: "8",
        9: "9",
        10: "Complete trust",
        77: "Refusal*",
        88: "Don't know*",
        99: "No answer*"

    },
    'slprl':{
             1: 	"None or almost none of the time",
             2: 	"Some of the time",
             3: 	"Most of the time",
             4: 	"All or almost all of the time",
             7: 	"Refusal*",
             8: 	"Don't know*",
             9: 	"No answer*"
             }
}
import pandas as pd
# Define the problematic responses set
problematic = {"Refusal*", "Don't know*", "No answer*","Not available*"}

# Create an empty dictionary to store the percentage for each column
overview_pct = {}

# Loop over each column defined in survey_dict that is present in dfsmall
for col, mapping in survey_dict.items():
    if col in dfsmall.columns:
        total = dfsmall[col].shape[0]
        count_problematic = dfsmall[col].apply(lambda x: mapping.get(x, None) in problematic).sum()
        pct = (count_problematic / total) * 100 if total > 0 else 0
        overview_pct[col] = pct

# Convert the dictionary to a DataFrame and sort descending by percentage
overview_pct_df = pd.DataFrame(list(overview_pct.items()), columns=['Column', 'Problematic Percentage'])
overview_pct_df = overview_pct_df.sort_values('Problematic Percentage', ascending=False)

print(overview_pct_df)

# Imputing Missing values
import numpy as np
import pandas as pd
from sklearn.impute import SimpleImputer

# Copy the original DataFrame to work on
dfimput = dfsmall.copy()

# Define problematic responses set
problematic = {"Refusal*", "Don't know*", "No answer*","Not available*"}

# Flag and convert problematic responses to NaN for each column
for col, mapping in survey_dict.items():
    if col in dfimput.columns:
        # Create a flag column indicating where problematic responses occurred
        flag_col = f"{col}_problematic"
        dfimput[flag_col] = dfimput[col].apply(lambda x: mapping.get(x, None) in problematic)

        # Replace problematic responses with NaN for imputation
        dfimput.loc[dfimput[flag_col], col] = np.nan

# Impute missing values using an appropriate strategy and then cast back to int:
for col in survey_dict:
    if col in dfimput.columns:
        # If the column is "agea", treat it as numeric; otherwise, treat it as categorical
        if col == 'agea':
            imputer = SimpleImputer(strategy='mean')
        else:
            imputer = SimpleImputer(strategy='most_frequent')

        # Impute the column; SimpleImputer expects a 2D array
        imputed = imputer.fit_transform(dfimput[[col]])

        # For agea (mean imputation) we may want to round before converting to int.
        # For categorical columns, the imputed values should already be integers.
        if col == 'agea':
            dfimput[col] = np.round(imputed).astype(int)
        else:
            dfimput[col] = imputed.astype(int)
 # Drop all columns ending with "_problematic"
cols_to_drop = [col for col in dfimput.columns if col.endswith("_problematic")]
dfimput_clean = dfimput.drop(columns=cols_to_drop)

# Count NaN values per column and sort descending
nan_counts = dfimput_clean.isna().sum().sort_values(ascending=False)
print(nan_counts)

# Descriptive statistics for features
import pandas as pd

# Assuming your DataFrame is named df
desc_stats = dfimput_clean.describe().T  # Transpose for variables as rows

# Round all statistics to 2 decimal places
desc_stats_rounded = desc_stats.round(2)

print(desc_stats_rounded[['count', 'mean', 'std', 'min', '25%', '50%', '75%', 'max']])

#=========================================Load the data from the CSV
import pandas as pd
dfimput_clean = pd.read_csv("/content/dfimput_clean.csv")

print(summary)

# Correlation Heatmap for dfimput_clean
import seaborn as sns
import matplotlib.pyplot as plt

# Compute the correlation matrix, excluding non-numeric columns
corr_matrix = dfimput_clean.select_dtypes(include=['number']).corr()

plt.figure(figsize=(22, 11))
sns.heatmap(corr_matrix, annot=True, fmt=".1f", cmap='coolwarm', vmin=-1, vmax=1, square=True)
plt.title("Correlation Heatmap ")
plt.show()

# Countplots and histogram of features
import matplotlib.pyplot as plt
import numpy as np
import seaborn as sns
import warnings
warnings.filterwarnings('ignore')

df = dfimput_clean  # Your DataFrame

features_to_plot = [col for col in df.columns if col not in ['happy', 'agea']]
n_plots = len(features_to_plot) + 1
num_cols = int(np.ceil(np.sqrt(n_plots)))
num_rows = int(np.ceil(n_plots / num_cols))

# Make the figure smaller and square
plt.figure(figsize=(8, 8))

# Plot histogram for 'agea'
plt.subplot(num_rows, num_cols, 1)
sns.histplot(df['agea'], kde=True, color='skyblue')
plt.title('Histogram of Age (agea)', fontsize=8)  # Small font

for i, feature in enumerate(features_to_plot):
    plt.subplot(num_rows, num_cols, i + 2)
    sns.countplot(x=df[feature], palette="Set2")
    plt.title(f'Countplot of {feature}', fontsize=8)  # Small font
    plt.xlabel('', fontsize=7)
    plt.ylabel('', fontsize=7)
    plt.xticks(fontsize=7)
    plt.yticks(fontsize=7)

plt.tight_layout()
plt.show()
plt.tight_layout()
plt.savefig('feature_plots.jpg', dpi=300, bbox_inches='tight')  # Save as JPG
plt.show()

# Correlation Coefficient
import pandas as pd
import matplotlib.pyplot as plt
import warnings
warnings.filterwarnings('ignore')

# Assuming dfimput_clean is your DataFrame and already loaded

# 1. Compute the correlation matrix for numeric columns
corr_matrix = dfimput_clean.select_dtypes(include=['number']).corr()

# 2. Extract correlation with 'happy' (excluding 'happy' itself) and sort
happy_corr = corr_matrix['happy'].drop('happy').sort_values()

# 3. Assign colors: green for positive, red for negative correlations
colors = happy_corr.apply(lambda x: 'blue' if x > 0 else 'red')

# 4. Plot horizontal bar chart
plt.figure(figsize=(10, 8))
plt.barh(happy_corr.index, happy_corr.values, color=colors)
plt.xlabel('Correlation Coefficient ')
plt.title('Correlation of Features with Target -happy-')
plt.grid(axis='x', linestyle='--', alpha=0.7)
plt.tight_layout()
plt.show()

columns_to_keep = ["happy",'stflife', 'stfeco', 'trstplc', 'stfdem', 'ppltrst', 'inprdsc', 'stfhlth',
    'sclmeet', 'trstlgl', 'sclact', 'hlthhmp', 'trstprl', 'netusoft', 'trstplt',
    'stfedu', 'stfgov', 'trstprt', 'hinctnta', 'trstun', 'trstep','slprl', 'health', 'flteeff', 'hincfel', 'fltlnl', 'fltsd'
]
remove_columns = ['agea', 'gndr', 'rlgdgr', 'dscrrce', 'uempli']


dfimput_clean=dfimput_clean[columns_to_keep]

# Convert target column :happy  into binary
import pandas as pd

# Load your dataset
df = pd.read_csv('dfimput_clean.csv')

# Create new column "happy_level" based on the value of 'happy'
def happy_category(val):
    if 0 <= val <= 5:
        return "Unhappy"
    elif 5 < val <= 10:
        return "Happy"

df['happy_level'] = df['happy'].apply(happy_category)

# Calculate the count and percentage for each category
counts = df['happy_level'].value_counts()
percentages = df['happy_level'].value_counts(normalize=True) * 100

# Combine counts and percentages into a DataFrame
summary = pd.DataFrame({
    'Count': counts,
    'Percentage': percentages
})

print("Summary of Happy Levels:")
dfimput_clean.to_csv("df_narrowed.csv", index=False)

import pandas as pd
df=pd.read_csv("/content/df_narrowed.csv")

#  Hyperparameter Tuning through CV for Random Forest for Recall 0
import numpy as np
import pandas as pd
from sklearn.model_selection import RandomizedSearchCV, StratifiedKFold
from sklearn.ensemble import RandomForestClassifier
from imblearn.over_sampling import SMOTE
from imblearn.under_sampling import RandomUnderSampler
from imblearn.pipeline import Pipeline
from sklearn.metrics import make_scorer, recall_score
from scipy.stats import randint
import warnings
warnings.filterwarnings("ignore")

# Prepare the data
X = df.drop('happy', axis=1)
y = df['happy']

# Set up the sampling strategy
sampling_pipeline = Pipeline([
    ('over', SMOTE(sampling_strategy=0.4, random_state=42)),
    ('under', RandomUnderSampler(sampling_strategy=0.6, random_state=42))
])

X_resampled, y_resampled = sampling_pipeline.fit_resample(X, y)

# Define the parameter grid for Random Forest
param_grid = {
    'n_estimators': randint(50, 500),
    'max_depth': [10, 20, 30, 40, 50, None],
    'min_samples_split': [2, 5, 10],
    'min_samples_leaf': [1, 2, 4],
    'bootstrap': [True, False]
}

# Initialize the model
model = RandomForestClassifier(random_state=42)

# Define the custom scorer for recall of the minority class (unhappy, class 0)
def recall_minority(y_true, y_pred):
    recall_values = recall_score(y_true, y_pred, average=None)  # Recall for each class
    return recall_values[0]  # Return recall for class 0 (unhappy)

scorer = make_scorer(recall_minority)

# Initialize Randomized Search
random_search = RandomizedSearchCV(
    estimator=model,
    param_distributions=param_grid,
    n_iter=50,
    scoring=scorer,
    cv=StratifiedKFold(n_splits=5, shuffle=True, random_state=42),
    random_state=42,
    n_jobs=-1
)

# Perform Randomized Search
random_search.fit(X_resampled, y_resampled)

# Print the best parameters and score
print("Best Parameters:", random_search.best_params_)
print("Best Recall for Minority Class (Unhappy, Class 0):", random_search.best_score_)

#  Hyperparameter Tuning through CV for XGBoost Recall class 0
import numpy as np
import pandas as pd
from sklearn.model_selection import RandomizedSearchCV, StratifiedKFold
from xgboost import XGBClassifier
from imblearn.over_sampling import SMOTE
from imblearn.under_sampling import RandomUnderSampler
from imblearn.pipeline import Pipeline
from sklearn.metrics import make_scorer, recall_score
import warnings
warnings.filterwarnings("ignore")

# Prepare the data
X = df.drop('happy', axis=1)
y = df['happy']

# Set up the sampling strategy
sampling_pipeline = Pipeline([
    ('over', SMOTE(sampling_strategy=0.4, random_state=42)),
    ('under', RandomUnderSampler(sampling_strategy=0.6, random_state=42))
])

X_resampled, y_resampled = sampling_pipeline.fit_resample(X, y)

# Define the parameter grid for XGBoost
param_grid = {
    'colsample_bytree': [0.6, 0.8, 1.0],
    'max_depth': [3, 6, 10],
    'min_child_weight': np.arange(1, 10, 1),
    'gamma': np.logspace(-2, 1, 10),
    'subsample': [0.6, 0.8, 1.0],
    'n_estimators': [50, 100, 200, 500],
    'learning_rate': [0.01, 0.1, 0.2]
}

# Initialize the model
model = XGBClassifier(
    use_label_encoder=False,
    eval_metric='logloss',
    random_state=42
)

# Define the custom scorer for recall of the minority class (class 0)
def recall_minority(y_true, y_pred):
    recall_values = recall_score(y_true, y_pred, average=None)  # Recall for each class
    return recall_values[0]  # Return recall for class 0 (minority)

scorer = make_scorer(recall_minority)

# Initialize Randomized Search
random_search = RandomizedSearchCV(
    estimator=model,
    param_distributions=param_grid,
    n_iter=50,
    scoring=scorer,
    cv=StratifiedKFold(n_splits=5, shuffle=True, random_state=42),
    random_state=42,
    n_jobs=-1
)

# Perform Randomized Search
random_search.fit(X_resampled, y_resampled)

# Print the best parameters and score
print("Best Parameters:", random_search.best_params_)
print("Best Recall for Minority Class (Unhappy, Class 0):", random_search.best_score_)

# Hyperparameter Tuning through CV for Logistic Regression  for Recall Class 0
import numpy as np
import pandas as pd
from sklearn.model_selection import RandomizedSearchCV, StratifiedKFold
from sklearn.linear_model import LogisticRegression
from sklearn.preprocessing import StandardScaler
from imblearn.over_sampling import SMOTE
from imblearn.under_sampling import RandomUnderSampler
from imblearn.pipeline import Pipeline
from sklearn.metrics import make_scorer, recall_score
from scipy.stats import uniform
import warnings
warnings.filterwarnings('ignore')


# Prepare the data
X = df.drop('happy', axis=1)
y = df['happy']

# Set up the sampling strategy
sampling_pipeline = Pipeline([
    ('over', SMOTE(sampling_strategy=0.4, random_state=42)),
    ('under', RandomUnderSampler(sampling_strategy=0.6, random_state=42))
])

X_resampled, y_resampled = sampling_pipeline.fit_resample(X, y)

# Define the parameter grid for Logistic Regression
param_grid = {
    'C': uniform(0.01, 100),
    'penalty': ['l1', 'l2', 'elasticnet'],
    'solver': ['liblinear', 'saga'],
    'class_weight': ['balanced', None]
}

# Initialize the model
model = LogisticRegression(max_iter=1000, random_state=42)

# Define the custom scorer for recall of the minority class (class 0)
def recall_minority(y_true, y_pred):
    recall_values = recall_score(y_true, y_pred, average=None)  # Recall for each class
    return recall_values[0]  # Return recall for class 0 (minority class)

scorer = make_scorer(recall_minority)

# Initialize Randomized Search
random_search = RandomizedSearchCV(
    estimator=model,
    param_distributions=param_grid,
    n_iter=50,
    scoring=scorer,
    cv=StratifiedKFold(n_splits=5, shuffle=True, random_state=42),
    random_state=42,
    n_jobs=-1
)

# Scale the data
scaler = StandardScaler()
X_rescaled = scaler.fit_transform(X_resampled)

# Perform Randomized Search
random_search.fit(X_rescaled, y_resampled)

# Print the best parameters and score
print("Best Parameters:", random_search.best_params_)
print("Best Recall for Minority Class (Unhappy, Class 0):", random_search.best_score_)

# Hyperparameter Tuning through CV for Lightgbm - Recall Unhappy 0
import numpy as np
import pandas as pd
from sklearn.model_selection import RandomizedSearchCV, StratifiedKFold
from lightgbm import LGBMClassifier
from imblearn.over_sampling import SMOTE
from imblearn.under_sampling import RandomUnderSampler
from imblearn.pipeline import Pipeline
from sklearn.metrics import make_scorer, f1_score, recall_score

# Prepare the data
X = df.drop('happy', axis=1)
y = df['happy']

# Set up the sampling strategy
sampling_pipeline = Pipeline([
    ('over', SMOTE(sampling_strategy=0.4, random_state=42)),
    ('under', RandomUnderSampler(sampling_strategy=0.6, random_state=42))
])

X_resampled, y_resampled = sampling_pipeline.fit_resample(X, y)

# Define the parameter grid for LightGBM
param_grid = {
    'num_leaves': np.arange(10, 50, 5),
    'max_depth': np.arange(3, 10, 1),
    'learning_rate': np.logspace(-3, 0, 10),
    'n_estimators': np.arange(50, 200, 25),
    'reg_alpha': [0, 0.1, 0.5, 1],
    'reg_lambda': [0, 0.1, 0.5, 1]
}

# Initialize the model
model = LGBMClassifier(random_state=42)

# Define the scorer
# Custom scorer to calculate recall for the minority class (unhappy, code 0)
def recall_unhappy(y_true, y_pred):
    recall_values = recall_score(y_true, y_pred, average=None)  # Get recall for each class
    return recall_values[0]  # Recall for unhappy class (class 0)

scorer = make_scorer(recall_unhappy)

# Initialize Randomized Search
random_search = RandomizedSearchCV(
    estimator=model,
    param_distributions=param_grid,
    n_iter=50,
    scoring=scorer,
    cv=StratifiedKFold(n_splits=5, shuffle=True, random_state=42),
    random_state=42,
    n_jobs=-1
)

# Perform Randomized Search
random_search.fit(X_resampled, y_resampled)

# Print the best parameters and score
print("Best Parameters:", random_search.best_params_)
print("Best Recall for Unhappy Class (Minority):", random_search.best_score_)

# SHAP-Random Forest
import numpy as np
import pandas as pd
import shap
import matplotlib.pyplot as plt
from sklearn.ensemble import RandomForestClassifier
from imblearn.over_sampling import SMOTE
from imblearn.under_sampling import RandomUnderSampler
from imblearn.pipeline import Pipeline
from sklearn.metrics import recall_score, make_scorer
from sklearn.model_selection import StratifiedKFold, RandomizedSearchCV
import warnings
warnings.filterwarnings("ignore")

# Categories
categories = {
    'Cognitive Well-Being': ['stfgov', 'stfdem', 'stfedu', 'stflife', 'stfeco'],
    'Social Well-Being': ['sclmeet', 'inprdsc', 'sclact'],
    'Affective Well-being': ['fltlnl', 'fltsd', 'flteeff', 'slprl'],
    'Institutional Trust': ['trstlgl', 'trstplc', 'trstplt', 'trstprl', 'trstprt', 'trstep', 'trstun', 'ppltrst'],
    'Health and Healthcare': ['health', 'hlthhmp', 'stfhlth'],
    'Socio-Economic': ['hinctnta', 'hincfel']
}

# Prepare the data
X = df.drop('happy', axis=1)
y = df['happy']

# Set up sampling strategy
sampling_pipeline = Pipeline([
    ('over', SMOTE(sampling_strategy=0.4, random_state=42)),
    ('under', RandomUnderSampler(sampling_strategy=0.6, random_state=42))
])

X_resampled, y_resampled = sampling_pipeline.fit_resample(X, y)

# Simplified parameter grid for Random Forest
param_grid = {
    'n_estimators': [50],  # Reduced number of trees
    'max_depth': [20],  # Reduced depth
    'min_samples_split': [2],
    'min_samples_leaf': [1],
    'bootstrap': [False]
}

# Initialize the model
model = RandomForestClassifier(random_state=42)

# Balanced scorer for both classes
scorer = make_scorer(recall_score, average='macro')

# Perform Randomized Search with fewer iterations and CV splits
random_search = RandomizedSearchCV(
    estimator=model,
    param_distributions=param_grid,
    n_iter=5,  # Further reduced iterations
    scoring=scorer,
    cv=StratifiedKFold(n_splits=3, shuffle=True, random_state=42),  # Fewer splits
    random_state=42,
    n_jobs=-1
)
random_search.fit(X_resampled, y_resampled)

# Train the model with the best parameters
best_model = random_search.best_estimator_

# Use an even smaller sample for SHAP analysis to reduce runtime
X_shap_sample = X_resampled.sample(n=50, random_state=42)

# Create SHAP explainer
explainer = shap.TreeExplainer(best_model)
shap_values = explainer(X_shap_sample)

# Select top 10 features based on model feature importance
top_features = np.argsort(best_model.feature_importances_)[-10:]
X_shap_sample_top = X_shap_sample.iloc[:, top_features]

# 1. SHAP Beeswarm Plot for All Features (Top 10 Features Only)
plt.title("SHAP Beeswarm Plot for Top 10 Features")
# Accessing SHAP values for the target class (e.g., class 1 - 'happy')
shap.plots.beeswarm(shap_values[:, :, 1], max_display=10)  # Assuming 'happy' is class 1
# Or for class 0 ('unhappy'): shap.plots.beeswarm(shap_values[:, :, 0], max_display=10)
plt.show()

# 2. Net Impact of Categories on the Target (Waterfall Plot)
category_shap_values = {}
for category, features in categories.items():
    category_indices = [X.columns.get_loc(f) for f in features if f in X.columns]
    category_shap_values[category] = np.sum(
        np.abs(shap_values[:, category_indices, 1].values), axis=(0, )  # Assuming target is class 1
    )

# Sort categories by net impact
sorted_categories = sorted(category_shap_values.items(), key=lambda x: x[1], reverse=True)
categories_sorted, net_impact = zip(*sorted_categories)

# Waterfall Plot for Net Impact
shap.waterfall_plot(
    shap.Explanation(
        values=np.array(net_impact),
        base_values=0,
        feature_names=categories_sorted
    ),
    max_display=5  # Limit to top 5 categories
)
plt.title("Net Impact of Categories on Target (Waterfall Plot)")
plt.show()

# 3. Positive and Negative Effects of Categories on the Target
positive_impact = {}
negative_impact = {}
for category, features in categories.items():
    category_indices = [X.columns.get_loc(f) for f in features if f in X.columns]
    shap_vals = shap_values[:, category_indices, 1].values  # Assuming target is class 1
    positive_impact[category] = np.sum(shap_vals[shap_vals > 0])
    negative_impact[category] = np.sum(shap_vals[shap_vals < 0])

# Combine positive and negative impacts for visualization
combined_impact = [
    ("Positive Impact", np.sum(list(positive_impact.values()))),
    ("Negative Impact", np.sum(list(negative_impact.values())))
]

# Waterfall Plot for Positive and Negative Effects
shap.waterfall_plot(
    shap.Explanation(
        values=[x[1] for x in combined_impact],
        base_values=0,
        feature_names=[x[0] for x in combined_impact]
    ),
    max_display=2  # Positive and Negative impacts
)
plt.title("Positive and Negative Effects of Categories on Target (Waterfall Plot)")
plt.show()

# Comparison Plot
import matplotlib.pyplot as plt

# Stages
stages = ['Stage 2 (CV)', 'Stage 3 (Tuning)']

# Model names
models = ['LightGBM', 'Logistic Regression', 'RandomForest', 'XGBoost']

# Recall values for each model at both stages
recall = {
    'LightGBM': [0.8125, 0.8457],
    'Logistic Regression': [0.8291, 0.8595],
    'RandomForest': [0.8025, 0.8679],
    'XGBoost': [0.6946, 0.8579]
}

# F1-score values for each model at both stages
f1_score = {
    'LightGBM': [0.7638, 0.8738],
    'Logistic Regression': [0.7403, 0.8504],
    'RandomForest': [0.7666, 0.8878],
    'XGBoost': [0.7569, 0.8821]
}

# Plot Recall
plt.figure(figsize=(8, 5))
for model in models:
    plt.plot(stages, recall[model], marker='o', label=model)
plt.title('Recall (Unhapp) Progress')
plt.ylabel('Recall')
plt.ylim(0.65, 0.9)
plt.legend()
plt.grid(True, linestyle='--', alpha=0.5)
plt.tight_layout()
plt.show()

# Plot F1-score
plt.figure(figsize=(8, 5))
for model in models:
    plt.plot(stages, f1_score[model], marker='o', label=model)
plt.title('F1-Score Progress')
plt.ylabel('F1-Score')
plt.ylim(0.7, 0.9)
plt.legend()
plt.grid(True, linestyle='--', alpha=0.5)
plt.tight_layout()
plt.show()